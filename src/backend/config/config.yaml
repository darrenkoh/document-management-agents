# Document Classification Agent Configuration

# Source directories to monitor for files (supports single path or list of paths)
# You can specify multiple directories to monitor:
# source_paths:
#   - "./input"
#   - "./documents"
#   - "/path/to/other/folder"
source_paths:
#  - "/Volumes/1TB/Private"
#  - "/Volumes/Documents/Private"
  - "/Volumes/Documents/Private/t"
  

# File extensions to process (REQUIRED - only files with these extensions will be processed)
# Empty list means NO files will be processed - you must specify extensions
# Common document formats:
file_extensions:
  - ".pdf"
  - ".docx"
  - ".doc"
  - ".txt"
  - ".png"
  - ".jpg"
  - ".jpeg"
  - ".gif"
  - ".tiff"

# Database configuration
database:
  # Path to the SQLite database file (high-performance DocumentDB)
  path: "data/databases/documents.db"
  # Vector database configuration
  vector_store:
    # Type of vector store: 'chromadb' or 'faiss'
    type: "chromadb"
    # Directory to persist vector data
    persist_directory: "data/vector_store"
    # Collection name for ChromaDB
    collection_name: "documents"
    # Embedding dimension (should match your embedding model)
    dimension: 4096
    # Distance metric for ChromaDB: 'l2', 'cosine', 'ip' (inner product)
    # 'cosine' is recommended for semantic search with normalized embeddings
    distance_metric: "cosine"

# Ollama configuration
ollama:
  # Ollama API endpoint (default: http://localhost:11434)
  endpoint: "http://spark-7819.local:11434"
  # Model name to use for classification
  model: "deepseek-r1:8b"
  # Timeout in seconds for API calls
  timeout: 300
  # Maximum number of tokens to predict (higher for reasoning models)
  num_predict: 6000
  # Embedding model for semantic search (default: qwen3-embedding:8b)
  embedding_model: "qwen3-embedding:8b"
  # Summarizer model for document summaries (default: deepseek-r1:8b)
  summarizer_model: "deepseek-r1:8b"
  # OCR model for fallback text extraction from images/PDFs
  # Set to 'chandra' to use Chandra OCR via vLLM (port 11435), or 'deepseek-ocr:3b' for Ollama (port 11434)
  ocr_model: "chandra"
  # Timeout for OCR operations (can be longer than regular models)
  ocr_timeout: 300
  # Retry configuration for failed LLM API calls
  retry:
    # Maximum number of retry attempts for failed API calls
    max_retries: 3
    # Delay in seconds between retry attempts (exponential backoff)
    base_delay: 1.0

# Chandra OCR configuration (vLLM-based)
chandra:
  # vLLM API endpoint for Chandra OCR (default: http://localhost:11435)
  endpoint: "http://spark-7819.local:11435"
  # Model name for Chandra in vLLM (default: chandra)
  model: "chandra"
  # Timeout for Chandra OCR operations in seconds
  timeout: 300
  # Maximum output tokens for Chandra OCR
  max_tokens: 16384
  # Retry configuration for failed Chandra API calls
  retry:
    # Maximum number of retry attempts for failed API calls
    max_retries: 3
    # Delay in seconds between retry attempts (exponential backoff)
    base_delay: 1.0
  # Frequency penalty to reduce repetition in generated text (0.0 to 2.0)
  frequency_penalty: 0.0
  # Whether to detect and retry on repetitive OCR output
  detect_repeat_tokens: false

# Optional: Predefined classification categories
# If empty, the agent will auto-detect categories
categories:
  - "Finance"
  - "Shopping"
  - "Travel"
  - "Home"
  - "School"
  - "Other"

# Classification prompt template
# Use {filename} and {content} as placeholders
# If not specified, a default prompt will be used
prompt_template: |
  Analyze the following document content and classify it into ONE main category and optionally up to 3 sub-categories.

  Main categories: Finance, Shopping, Travel, Home, School, Other

  Classification Rules:
  - Finance: Documents related to bank statements, investments, 401K, W2 forms, car registration, car insurance, financial statements, tax documents, or any financial transactions
  - Shopping: Documents related to purchases, receipts, invoices, or buying goods and services
  - Travel: Documents related to bookings, tickets, itineraries, reservations, or travel plans
  - Home: Documents related to home improvement, property tax, home loan, home insurance, utility bills, or home maintenance
  - School: Documents related to education, courses, grades, transcripts, or academic materials
  - Other: Anything that doesn't fit the above categories

  Filename: {filename}

  Content:
  {content}

  First, classify this document into ONE main category from the list above. Then, if the document would benefit from additional context beyond the main category (especially if the main category is "Other"), suggest up to 3 specific sub-categories that describe the document's content more precisely. The sub-category word should not be longer than 2 words.

  IMPORTANT: After your analysis, provide ONLY your final answer in this exact format in the response field (not in thinking):
  MAIN: [main category]
  SUB: [sub-category1, sub-category2, sub-category3] (or leave empty if no sub-categories needed)

  Examples:
  MAIN: Finance
  SUB: invoice, tax, quarterly

  MAIN: Other
  SUB: medical, prescription, pharmacy

  MAIN: Travel
  SUB: (leave empty)

  Use lowercase for sub-categories and separate with commas.

# Watch mode settings
watch:
  # Polling interval in seconds (for watch mode)
  interval: 5
  # Recursively watch subdirectories
  recursive: true

# Web app configuration
webapp:
  # Port to run the web application on
  port: 8081
  # Host to bind the web application to (0.0.0.0 for all interfaces)
  host: "0.0.0.0"
  # Enable debug mode (set to false for production)
  debug: true

# Semantic search configuration
semantic_search:
  # Default number of results to return
  top_k: 10
  # Minimum similarity threshold (0.0 to 1.0)
  # Lower values return more results, higher values return more precise results
  min_similarity_threshold: 0.1
  # Maximum number of results to retrieve before filtering (for better ranking)
  max_candidates: 30
  # Enable debug logging for similarity calculations
  debug_similarity: true
  # Enable RAG (Retrieval-Augmented Generation) analysis
  # When enabled, retrieved documents are analyzed by LLM for relevance
  enable_rag: true
  # Minimum relevance score threshold for RAG filtering (0.0 to 1.0)
  # Documents below this score may be filtered out
  rag_relevance_threshold: 0.3

# Document chunking configuration for embeddings
chunking:
  # Maximum characters per chunk (optimized for qwen3-embedding:8b with 32K context)
  chunk_size: 12000
  # Characters to overlap between chunks
  chunk_overlap: 200
  # Whether to generate summary embeddings for documents
  enable_summary_embedding: true

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "data/agent.log"

